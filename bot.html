<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Voice Assistant</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
    <style>
        :root {
            --primary: #6c5ce7;
            --secondary: #a29bfe;
            --accent: #fd79a8;
            --light: #f5f6fa;
            --dark: #2d3436;
        }
    
        * {
            box-sizing: border-box;
            margin: 0;
            padding: 0;
        }
    
        #ai-assistant {
            position: fixed;
            bottom: 30px;
            right: 30px;
            z-index: 1000;
        }
    
        #assistant-toggle {
            width: 60px;
            height: 60px;
            border-radius: 50%;
            background: var(--primary);
            color: white;
            border: none;
            font-size: 24px;
            cursor: pointer;
            box-shadow: 0 4px 20px rgba(0,0,0,0.2);
            transition: all 0.3s ease;
            display: flex;
            align-items: center;
            justify-content: center;
        }
    
        #assistant-toggle:hover {
            transform: scale(1.1);
            background: var(--accent);
        }
    
        .assistant-panel {
            position: absolute;
            bottom: 80px;
            right: 0;
            width: 700px;
            height: 570px;
            background: white;
            border-radius: 16px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.15);
            display: none;
            flex-direction: column;
            overflow: hidden;
            transform: translateY(20px);
            opacity: 0;
            transition: all 0.3s ease;
        }
    
        .assistant-panel.active {
            display: flex;
            transform: translateY(0);
            opacity: 1;
        }
    
        .panel-header {
            padding: 15px 20px;
            background: linear-gradient(to right, var(--primary), var(--accent));
            color: white;
            display: flex;
            align-items: center;
            justify-content: space-between;
        }
    
        .avatar-container {
            width: 100px;
            height: 100px;
            margin: 10px auto;
            position: relative;
            display: none;
        }
    
        #Layer_1 .mouth-path {
            transform-origin: center;
            transition: all 0.1s ease;
        }
    
        .talking #Layer_1 .mouth-path {
            animation: mouth-animation 0.2s infinite alternate;
            transform-box: fill-box;
        }
    
        @keyframes mouth-animation {
            0% { transform: scaleY(1) scaleX(1); }
            25% { transform: scaleY(0.8) scaleX(1.1); }
            50% { transform: scaleY(1.1) scaleX(0.9); }
            75% { transform: scaleY(0.9) scaleX(1.05); }
            100% { transform: scaleY(1.05) scaleX(0.95); }
        }
    
        .chat-display {
            flex-grow: 1;
            padding: 20px;
            overflow-y: auto;
            background: var(--light);
            display: flex;
            flex-direction: column;
            scroll-behavior: smooth;
        }
    
        .message {
            max-width: 85%;
            padding: 12px 16px;
            border-radius: 18px;
            margin-bottom: 15px;
            line-height: 1.5;
            animation: fadeIn 0.3s ease;
            word-wrap: break-word;
            white-space: pre-wrap;
        }
    
        .user-message {
            background: var(--primary);
            color: white;
            margin-left: auto;
            border-bottom-right-radius: 5px;
            align-self: flex-end;
        }
    
        .ai-message {
            background: white;
            color: var(--dark);
            margin-right: auto;
            border-bottom-left-radius: 5px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
            align-self: flex-start;
            overflow-wrap: break-word;
        }
    
        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(10px); }
            to { opacity: 1; transform: translateY(0); }
        }
    
        .input-area {
            padding: 15px;
            border-top: 1px solid #eee;
            background: white;
        }
    
        .input-container {
            display: flex;
            gap: 10px;
            margin-bottom: 15px;
            align-items: flex-end;
        }
    
        #text-input {
            flex: 1;
            min-height: 42px;
            max-height: 120px;
            padding: 12px 15px;
            border: 1px solid #ddd;
            border-radius: 25px;
            outline: none;
            font-size: 14px;
            resize: none;
            overflow-y: auto;
            line-height: 1.4;
        }
    
        #send-btn {
            width: 42px;
            height: 42px;
            min-width: 42px;
            border-radius: 50%;
            border: none;
            background: var(--primary);
            color: white;
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: center;
        }
    
        .mode-selector {
            display: flex;
            justify-content: space-around;
            padding: 10px;
            background: var(--light);
            border-radius: 25px;
        }
    
        .mode-option {
            display: flex;
            flex-direction: column;
            align-items: center;
            cursor: pointer;
            padding: 5px 10px;
            border-radius: 15px;
            transition: all 0.3s ease;
        }
    
        .mode-option.active {
            background: var(--primary);
            color: white;
        }
    
        .mode-option i {
            margin-bottom: 5px;
        }
    
        .voice-control {
            width: 100%;
            height: 40px;
            border-radius: 25px;
            background: var(--primary);
            color: white;
            border: none;
            display: none;
            align-items: center;
            justify-content: center;
            cursor: pointer;
            margin-top: 10px;
            transition: all 0.3s ease;
        }
    
        .voice-control.listening {
            background: var(--accent);
            animation: pulse 1.5s infinite;
        }
    
        @keyframes pulse {
            0% { box-shadow: 0 0 0 0 rgba(253, 121, 168, 0.7); }
            70% { box-shadow: 0 0 0 10px rgba(253, 121, 168, 0); }
            100% { box-shadow: 0 0 0 0 rgba(253, 121, 168, 0); }
        }
        
        /* Voice chat status area */
        .voice-status {
            text-align: center;
            padding: 5px;
            margin-top: 5px;
            font-size: 14px;
            color: var(--dark);
            font-weight: bold;
            height: 24px;
        }
    
        @media (max-width: 767px) {
            .assistant-panel {
                width: 100vw;
                height: 100vh;
                bottom: 0;
                right: 0;
                border-radius: 0;
            }
            
            .message {
                max-width: 90%;
            }
        }
    </style>
</head>
<body>
    <div id="ai-assistant">
        <button id="assistant-toggle">
            <i class="fas fa-robot"></i>
        </button>
        
        <div class="assistant-panel">
            <div class="panel-header">
                <h3>AI Assistant</h3>
                <button id="close-panel"><i class="fas fa-times"></i></button>
            </div>
            
            <div class="chat-display" id="chat-display">
                <div class="message ai-message">
                    Hello! This is Silverlink How can we help you today?
                </div>
            </div>
            
            <div class="avatar-container" id="avatar-container">
                <svg viewBox="0 0 128 128" data-name="Layer 1" id="Layer_1" xmlns="http://www.w3.org/2000/svg">
                    <circle class="cls-1" cx="64" cy="64" r="60" fill="#4bc190"></circle>
                    <circle class="cls-2" cx="64" cy="64" r="48" fill="#356cb6" opacity="0.3"></circle>
                    <path class="cls-3" d="M31.08,61.57V45.92a32.92,32.92,0,0,1,65.84,0V61.57Z" fill="#393c54"></path>
                    <circle class="cls-4" cx="91.32" cy="60.43" r="7.93" fill="#fba875"></circle>
                    <path class="cls-5" d="M64,124.1a59.78,59.78,0,0,0,40-15.28l-2.39-5.68c-1.71-4-6.22-6.64-11.29-6.64H37.69c-5.07,0-9.58,2.66-11.29,6.64L24,108.82A59.78,59.78,0,0,0,64,124.1Z" fill="#ffffff"></path>
                    <path class="cls-5" d="M81.72,98.25a3.06,3.06,0,0,0-3.08-2.88H49.36a3.07,3.07,0,0,0-3.08,2.93c0,.11,0,.21,0,.32-.17,7.32,10.52,16.64,10.52,16.64L64,108.05l7.17,7.17s10.56-9,10.56-16.22C81.73,98.74,81.73,98.49,81.72,98.25Z" fill="#ffffff"></path>
                    <line class="cls-6" x1="64" x2="64" y1="84.75" y2="98.5" stroke="#fba875" stroke-width="20" stroke-linecap="round" stroke-miterlimit="10"></line>
                    <circle class="cls-4" cx="36.68" cy="60.43" r="7.93" fill="#fba875"></circle>
                    <path class="cls-7" d="M64,94.37A28.31,28.31,0,0,1,35.68,66.05V47.43a28.32,28.32,0,1,1,56.64,0V66.05A28.31,28.31,0,0,1,64,94.37Z" fill="#ffbb94"></path>
                    <circle class="cls-3" cx="76.67" cy="59.28" r="3" fill="#393c54"></circle>
                    <circle class="cls-3" cx="49.67" cy="59.28" r="3" fill="#393c54"></circle>
                    <line class="cls-8" x1="74.39" x2="84" y1="53" y2="52.75" stroke="#515570" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" opacity="0.4"></line>
                    <line class="cls-8" x1="53" x2="43.39" y1="53" y2="52.75" stroke="#515570" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" opacity="0.4"></line>
                    <path class="mouth-path cls-3" d="M71.55,74a1,1,0,0,1,.94,1.07,8.56,8.56,0,0,1-17,0A1,1,0,0,1,56.45,74Z" fill="#393c54"></path>
                    <line class="cls-8" x1="60" x2="68" y1="86" y2="86" stroke="#515570" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" opacity="0.4"></line>
                    <line class="cls-9" x1="63.35" x2="63.35" y1="60.75" y2="67.25" stroke="#fba875" stroke-width="4" stroke-linecap="round" stroke-miterlimit="10"></line>
                    <line class="cls-9" x1="66" x2="61" y1="68" y2="68" stroke="#fba875" stroke-width="4" stroke-linecap="round" stroke-miterlimit="10"></line>
                    <path class="cls-10" d="M59,80.91a8.52,8.52,0,0,0,10.08,0,5.79,5.79,0,0,0-10.08,0Z" fill="#f85565"></path>
                    <path class="cls-5" d="M69,76H59a1.84,1.84,0,0,1-1.73-2H70.77A1.84,1.84,0,0,1,69,76Z" fill="#ffffff"></path>
                    <path class="cls-11" d="M64,16.85a30,30,0,0,0-30,30V53a4,4,0,0,0,4-4V41.56a4.18,4.18,0,0,1,4.18-4.18h7.36A20.61,20.61,0,0,0,64,42.77a20.61,20.61,0,0,0,14.41-5.39h7.36A4.18,4.18,0,0,1,90,41.56v7.35a4,4,0,0,0,4,4V46.84A30,30,0,0,0,64,16.85Z" fill="#515570"></path>
                </svg>
            </div>
            
            <div class="input-area">
                <div class="input-container" id="text-input-container">
                    <textarea id="text-input" placeholder="Type your message..." rows="1"></textarea>
                    <button id="send-btn"><i class="fas fa-paper-plane"></i></button>
                </div>
                
                <div class="mode-selector">
                    <div class="mode-option active" data-mode="text">
                        <i class="fas fa-comment"></i>
                        <span>Text</span>
                    </div>
                    <div class="mode-option" data-mode="voice">
                        <i class="fas fa-volume-up"></i>
                        <span>Voice</span>
                    </div>
                    <div class="mode-option" data-mode="avatar">
                        <i class="fas fa-robot"></i>
                        <span>Avatar</span>
                    </div>
                </div>
                
                <div class="voice-controls">
                    <button id="start-chat" class="voice-control">
                        <i class="fas fa-microphone"></i> Start Voice Chat
                    </button>
                    <button id="end-chat" class="voice-control" style="background-color: var(--accent); display: none;">
                        <i class="fas fa-stop-circle"></i> End Voice Chat
                    </button>
                    <div class="voice-status" id="status">Ready to start</div>
                </div>
            </div>
        </div>
    </div>
<script>
    // Global variables for managing state
let mediaRecorder;
let audioChunks = [];
let silenceTimeout;
let isListening = false;
let isSpeaking = false;
let userEndedChat = false;
let audioContext;
let analyser;
let source;
let silenceDetectionActive = false;
let voiceDetected = false;
let messageCount = 0;
let activeRequestId = null;
const MAX_MESSAGES = 100;

// DOM elements
const chatDisplay = document.getElementById("chat-display") || createFallbackElement("div", "chat-display");
const textInput = document.getElementById("text-input") || createFallbackElement("textarea", "text-input");
const sendBtn = document.getElementById("send-btn") || createFallbackElement("button", "send-btn");
const assistantToggle = document.getElementById("assistant-toggle") || createFallbackElement("button", "assistant-toggle");
const closePanel = document.getElementById("close-panel") || createFallbackElement("button", "close-panel");
const assistantPanel = document.querySelector(".assistant-panel") || createFallbackElement("div", "assistant-panel");
const modeOptions = document.querySelectorAll(".mode-option") || [];
const voiceControl = document.getElementById("start-chat") || createFallbackElement("button", "start-chat");
const endChat = document.getElementById("end-chat") || createFallbackElement("button", "end-chat");
const avatarContainer = document.getElementById("avatar-container") || createFallbackElement("div", "avatar-container");
const textInputContainer = document.getElementById("text-input-container") || createFallbackElement("div", "text-input-container");
const statusEl = document.getElementById("status") || createFallbackElement("div", "status");
const clearChatBtn = document.createElement("button");
clearChatBtn.id = "clear-chat";
clearChatBtn.className = "clear-chat-btn";
clearChatBtn.textContent = "Clear Chat";
assistantPanel.appendChild(clearChatBtn);

// Create fallback element if not found in DOM
function createFallbackElement(type, id) {
    console.warn(`Element ${id} not found, creating fallback`);
    const el = document.createElement(type);
    el.id = id;
    document.body.appendChild(el);
    return el;
}

// Replace with your actual webhook URL
const webhookUrl = "https://hasnat4554.app.n8n.cloud/webhook/f230f636-ebbc-4bd5-b8ab-143bbe306370"; 

// Session ID for grouping messages
const sessionId = Date.now() + Math.random().toString(36).substr(2, 9);

// Function to start recording
async function startListening() { 
    if (isListening || userEndedChat) return;
    
    try {
        isListening = true;
        voiceDetected = false;
        updateStatus("Listening...");
        
        // Stop any existing stream and analyzer
        cleanupAudioResources(false);
        
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        
        mediaRecorder = new MediaRecorder(stream);
        audioChunks = []; // Clear previous chunks
        
        mediaRecorder.ondataavailable = (event) => {
            if (event.data.size > 0) {
                audioChunks.push(event.data);
            }
        };

        mediaRecorder.onstop = () => {
            if (audioChunks.length > 0 && voiceDetected) {
                const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                if (audioBlob.size > 100) {
                    sendAudioToWebhook(audioBlob);
                } else {
                    updateStatus("Audio too quiet, listening again...");
                    setTimeout(() => {
                        if (!userEndedChat) startListening();
                    }, 1000);
                }
            } else {
                updateStatus("No voice detected, listening again...");
                setTimeout(() => {
                    if (!userEndedChat) startListening();
                }, 1000);
            }
        };

        mediaRecorder.start();
        endChat.style.display = "flex";
        voiceControl.style.display = "none";
        
        // Start silence detection
        detectSilence(stream);
        
        // Safety timeout
        silenceTimeout = setTimeout(() => {
            if (isListening && !voiceDetected) {
                updateStatus("Listening timeout, restarting...");
                stopListening();
            }
        }, 30000);
        
    } catch (error) {
        console.error("Error starting recording:", error);
        
        if (error.name === "NotAllowedError") {
            updateStatus("Microphone access denied");
            addMessage("Please allow microphone access to use voice chat.", "system");
        } else if (error.name === "NotFoundError") {
            updateStatus("No microphone found");
            addMessage("No microphone detected. Please connect a microphone or switch to text mode.", "system");
        } else {
            updateStatus("Error starting microphone");
            addMessage("There was a problem accessing your microphone. You can still use text chat.", "system");
        }
        
        isListening = false;
        voiceControl.style.display = "flex";
        endChat.style.display = "none";
    }
}

// Function to stop recording
function stopListening() {
    if (!isListening) return;
    
    isListening = false;
    if (silenceTimeout) {
        clearTimeout(silenceTimeout);
        silenceTimeout = null;
    }
    
    if (mediaRecorder && mediaRecorder.state !== "inactive") {
        try {
            mediaRecorder.stop();
        } catch (error) {
            console.error("Error stopping media recorder:", error);
        }
    }
}

// Silence detection function
async function detectSilence(stream) {
    if (silenceDetectionActive) return;
    
    silenceDetectionActive = true;
    let animationFrame = null;
    
    try {
        // Setup audio context and analyzer
        if (!audioContext) {
            audioContext = new (window.AudioContext || window.webkitAudioContext)();
        }
        
        if (!analyser) {
            analyser = audioContext.createAnalyser();
            analyser.minDecibels = -85;
            analyser.maxDecibels = -10;
            analyser.smoothingTimeConstant = 0.85;
            analyser.fftSize = 256;
        }
        
        if (!source) {
            source = audioContext.createMediaStreamSource(stream);
            source.connect(analyser);
        }
        
        const bufferLength = analyser.frequencyBinCount;
        const dataArray = new Uint8Array(bufferLength);
        
        let silenceStart = null;
        let voiceThresholdMet = false;
        
        const SILENCE_THRESHOLD = 5;
        const VOICE_THRESHOLD = 15;
        const SILENCE_DURATION = 2000;
        
        function checkSilence() {
            if (userEndedChat || !silenceDetectionActive) {
                cancelAnimationFrame(animationFrame);
                silenceDetectionActive = false;
                return;
            }
            
            if (!isListening && !isSpeaking) {
                animationFrame = requestAnimationFrame(checkSilence);
                return;
            }
            
            analyser.getByteFrequencyData(dataArray);
            
            // Calculate average volume with frequency weighting
            let sum = 0;
            let count = 0;
            
            const voiceStartBin = Math.floor(85 * bufferLength / (audioContext.sampleRate / 2));
            const voiceEndBin = Math.floor(255 * bufferLength / (audioContext.sampleRate / 2));
            
            for (let i = 0; i < bufferLength; i++) {
                const weight = (i >= voiceStartBin && i <= voiceEndBin) ? 1.5 : 1.0;
                sum += dataArray[i] * weight;
                count += weight;
            }
            
            const average = sum / count;
            const now = Date.now();
            
            // Check if voice is detected
            if (average >= VOICE_THRESHOLD && isListening) {
                voiceDetected = true;
                voiceThresholdMet = true;
                silenceStart = null;
                updateStatus("Voice detected");
            } else if (average < SILENCE_THRESHOLD && isListening) {
                // Silence detected
                if (voiceDetected && !silenceStart) {
                    silenceStart = now;
                    updateStatus("Listening for more...");
                } else if (voiceDetected && silenceStart && (now - silenceStart > SILENCE_DURATION)) {
                    silenceStart = null;
                    updateStatus("Processing...");
                    stopListening();
                    cancelAnimationFrame(animationFrame);
                    silenceDetectionActive = false;
                    return;
                }
            } else if (average >= SILENCE_THRESHOLD && average < VOICE_THRESHOLD && isListening) {
                silenceStart = null;
                updateStatus("Listening...");
            }
            
            animationFrame = requestAnimationFrame(checkSilence);
        }
        
        animationFrame = requestAnimationFrame(checkSilence);
        
    } catch (error) {
        console.error("Error in silence detection:", error);
        silenceDetectionActive = false;
    }
}

// Clean up audio resources
function cleanupAudioResources(complete = true) {
    silenceDetectionActive = false;
    
    if (mediaRecorder && mediaRecorder.state !== "inactive") {
        try {
            mediaRecorder.stop();
        } catch (error) {
            console.error("Error stopping mediaRecorder:", error);
        }
    }
    
    if (source) {
        try {
            source.disconnect();
            if (complete) source = null;
        } catch (error) {
            console.error("Error disconnecting source:", error);
        }
    }
    
    if (complete && audioContext) {
        try {
            audioContext.close().catch(err => console.error("Error closing audio context:", err));
            audioContext = null;
            analyser = null;
        } catch (error) {
            console.error("Error closing audioContext:", error);
        }
    }
}

// Send audio to webhook with simultaneous processing
function sendAudioToWebhook(audioBlob) { 
    const requestId = Date.now().toString();
    activeRequestId = requestId;
    
    const formData = new FormData();
    formData.append("audio", audioBlob, "audio.webm");
    formData.append("timestamp", new Date().toISOString());
    formData.append("sessionId", sessionId);
    formData.append("requestId", requestId);
    formData.append("processType", "both"); // Request both text and audio processing
    
    updateStatus("Processing your message...");
    
    // Show processing message in chat
    const processingMsgId = "processing-" + requestId;
    addMessage("Processing your voice message...", "system", processingMsgId);

   

    fetch(webhookUrl, {
        method: "POST",
        body: formData,
        headers: {
            "X-Process-Mode": "both" // Additional header to indicate we want both text and audio
        }
    })
    .then(response => {
        clearTimeout(timeoutId);
        
        if (!response.ok) {
            throw new Error(`Server responded with ${response.status}`);
        }
        
        // Get the text response from the header (assuming webhook returns it)
        const textResponse = response.headers.get("X-Text-Response") || "Assistant's response";
        
        // Check content type to handle different response types
        const contentType = response.headers.get("content-type");
        if (contentType && contentType.includes("audio")) {
            return response.blob().then(blob => ({
                type: "both", 
                textData: textResponse, 
                audioData: blob
            }));
        } else {
            return response.text().then(text => ({
                type: "text", 
                textData: text, 
                audioData: null
            }));
        }
    })
    .then(result => {
        // Remove processing message
        removeMessage(processingMsgId);

        // Add the text response to chat
        const textMessage = result.textData || "Assistant's response";
        const textMsgElement = addMessage(sanitizeMessage(textMessage), "ai");
        
        // Play audio if available and appropriate
        if (result.type === "both" && result.audioData) {
            playAudio(result.audioData);
        }
        
        activeRequestId = null;
        
        // If in voice mode, restart listening after a short delay
        if (document.querySelector(".mode-option[data-mode='voice']").classList.contains("active") && !userEndedChat) {
            setTimeout(() => {
                startListening();
            }, 1000);
        }
    })
    .catch(error => {
        clearTimeout(timeoutId);
        console.error("Error sending/receiving audio:", error);
        updateStatus("Error. Try again.");
        
        // Update the processing message with error
        updateMessage(processingMsgId, "Error processing your message. Please try again.", "system");
        
        activeRequestId = null;

        // After error, wait a bit and restart listening if in voice mode
        if (document.querySelector(".mode-option[data-mode='voice']").classList.contains("active") && !userEndedChat) {
            setTimeout(() => {
                startListening();
            }, 3000);
        }
    });
}

// Function to play audio response
function playAudio(audioBlob) {
    if (userEndedChat) return;
    
    const audioUrl = URL.createObjectURL(audioBlob);
    const audio = new Audio(audioUrl);
    
    isSpeaking = true;
    updateStatus("Speaking...");
    avatarContainer.classList.add("talking");
    
    const messageId = "audio-" + Date.now();
    // We don't need to add a separate audio message as we now have the text too
    
    audio.addEventListener('playing', () => {
        avatarContainer.classList.add("pulse-animation");
    });
    
    audio.addEventListener('ended', () => handleAudioComplete(true));
    audio.addEventListener('error', handleAudioError);
    
    audio.play().catch(error => {
        console.error("Error playing audio:", error);
        handleAudioError();
    });
    
    function handleAudioComplete(completedNormally) {
        isSpeaking = false;
        avatarContainer.classList.remove("talking");
        avatarContainer.classList.remove("pulse-animation");
        
        // Clean up URL object
        URL.revokeObjectURL(audioUrl);
        
        if (!userEndedChat && document.querySelector(".mode-option[data-mode='voice']").classList.contains("active")) {
            updateStatus("Ready to listen");
            setTimeout(() => startListening(), 1000);
        }
    }
    
    function handleAudioError() {
        isSpeaking = false;
        avatarContainer.classList.remove("talking");
        avatarContainer.classList.remove("pulse-animation");
        URL.revokeObjectURL(audioUrl);
        
        addMessage("Error playing audio. The text response is still available.", "system");
        
        if (!userEndedChat && document.querySelector(".mode-option[data-mode='voice']").classList.contains("active")) {
            updateStatus("Audio error. Resuming...");
            setTimeout(() => startListening(), 2000);
        }
    }
}

// Send text message to webhook with simultaneous processing
function sendTextToWebhook(text) {
    if (!text || !text.trim()) return;
    
    const requestId = Date.now().toString();
    activeRequestId = requestId;
    
    // Display user message in chat
    addMessage(sanitizeMessage(text), "user");
    
    // Create form data
    const formData = new FormData();
    formData.append("text", text);
    formData.append("timestamp", new Date().toISOString());
    formData.append("sessionId", sessionId);
    formData.append("requestId", requestId);
    formData.append("processType", "both"); // Request both text and audio processing
    
    // Show processing indicator
    const processingMsgId = "processing-" + requestId;
    addMessage("Processing your message...", "system", processingMsgId);
    
    // Add timeout for long-running requests
    const timeoutId = setTimeout(() => {
        if (activeRequestId === requestId) {
            updateMessage(processingMsgId, "The request is taking longer than expected. Please wait.", "system");
        }
    }, 20000);
    
    fetch(webhookUrl, {
        method: "POST",
        body: formData,
        headers: {
            "X-Process-Mode": "both" // Additional header to indicate we want both text and audio
        }
    })
    .then(response => {
        clearTimeout(timeoutId);
        
        if (!response.ok) {
            throw new Error(`Server responded with ${response.status}`);
        }
        
        // Get the text response from the header (assuming webhook returns it)
        const textResponse = response.headers.get("X-Text-Response");
        
        // Check content type to handle different response types
        const contentType = response.headers.get("content-type");
        
        // Handle both audio and text responses
        if (contentType && contentType.includes("audio")) {
            return response.blob().then(blob => ({
                type: "both", 
                textData: textResponse || "Your request is being processed", 
                audioData: blob
            }));
        } else {
            return response.text().then(text => ({
                type: "text", 
                textData: text, 
                audioData: null
            }));
        }
    })
    .then(result => {
        // Remove processing message
        removeMessage(processingMsgId);
        
        // Add the text response to chat
        const textMessage = result.textData || "Assistant's response";
        addMessage(sanitizeMessage(textMessage), "ai");
        
        // If we have avatar mode active or we're in voice mode, play the audio
        const shouldPlayAudio = 
            (document.querySelector(".mode-option[data-mode='avatar']").classList.contains("active") ||
             document.querySelector(".mode-option[data-mode='voice']").classList.contains("active")) &&
            result.type === "both" && 
            result.audioData;
            
        if (shouldPlayAudio) {
            playAudio(result.audioData);
        }
        
        activeRequestId = null;
    })
    .catch(error => {
        clearTimeout(timeoutId);
        console.error("Error sending/receiving text:", error);
        
        // Update the processing message with error
        updateMessage(processingMsgId, "Error processing your message. Please try again.", "system");
        
        activeRequestId = null;
    });
}

// Sanitize message to prevent XSS
function sanitizeMessage(text) {
    if (!text) return "";
    const div = document.createElement('div');
    div.textContent = text;
    return div.innerHTML;
}

// Function to add messages to chat display
function addMessage(text, sender, id = null) {
    const messageElement = document.createElement("div");
    messageElement.className = `message ${sender}-message`;
    if (id) messageElement.id = id;
    
    messageElement.innerHTML = text;
    
    chatDisplay.appendChild(messageElement);
    chatDisplay.scrollTop = chatDisplay.scrollHeight;
    
    // Count messages and cleanup if needed
    messageCount++;
    if (messageCount > MAX_MESSAGES) {
        cleanupOldMessages();
    }
    
    return messageElement;
}

// Update an existing message
function updateMessage(id, text, sender = null) {
    const messageElement = document.getElementById(id);
    
    if (messageElement) {
        if (sender) {
            messageElement.className = `message ${sender}-message`;
        }
        
        messageElement.innerHTML = text;
        chatDisplay.scrollTop = chatDisplay.scrollHeight;
    }
}

// Remove a message
function removeMessage(id) {
    const messageElement = document.getElementById(id);
    if (messageElement) {
        messageElement.remove();
        messageCount--;
    }
}

// Clean up old messages to prevent memory issues
function cleanupOldMessages() {
    const messages = chatDisplay.querySelectorAll('.message');
    
    const messagesToRemove = messages.length - MAX_MESSAGES;
    
    if (messagesToRemove > 0) {
        for (let i = 0; i < messagesToRemove; i++) {
            if (messages[i]) {
                messages[i].remove();
                messageCount--;
            }
        }
        
        // Add a message indicating some history was removed
        const notice = document.createElement("div");
        notice.className = "message system-message";
        notice.textContent = `[${messagesToRemove} older messages were removed to improve performance]`;
        chatDisplay.insertBefore(notice, chatDisplay.firstChild);
    }
}

// Update status with visual indication
function updateStatus(text) {
    if (!statusEl) return;
    
    statusEl.innerText = text;
    
    // Visual feedback with brief highlight
    statusEl.classList.add("status-update");
    setTimeout(() => {
        statusEl.classList.remove("status-update");
    }, 300);
}

// Clear chat history
function clearChat() {
    while (chatDisplay.firstChild) {
        chatDisplay.removeChild(chatDisplay.firstChild);
    }
    messageCount = 0;
    addMessage("Chat history cleared", "system");
}

// End voice chat and clean up resources
function endVoiceChat() {
    userEndedChat = true;
    
    if (isListening) {
        stopListening();
    }
    
    cleanupAudioResources(true);
    
    voiceControl.classList.remove("listening");
    voiceControl.style.display = "flex";
    endChat.style.display = "none";
    
    updateStatus("Voice chat ended");
}

// Clean up resources when window/tab is closed
function cleanupResources() {
    cleanupAudioResources(true);
}

// Send initial ping to the webhook
function sendInitialPing() {
    fetch(webhookUrl, {
        method: "POST",
        body: JSON.stringify({
            type: "ping",
            sessionId: sessionId,
            timestamp: new Date().toISOString()
        }),
        headers: {
            "Content-Type": "application/json"
        }
    }).catch(error => {
        console.error("Error sending initial ping:", error);
    });
}

// Initialize the UI components and event listeners
function initializeApp() {
    // Add basic styling for the status update animation and avatar pulse
    const style = document.createElement('style');
    style.textContent = `
        .status-update {
            animation: statusPulse 0.3s ease-in-out;
        }
        @keyframes statusPulse {
            0% { opacity: 0.5; }
            50% { opacity: 1; }
            100% { opacity: 0.5; }
        }
        .pulse-animation {
            animation: avatarPulse 2s infinite;
        }
        @keyframes avatarPulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.05); }
            100% { transform: scale(1); }
        }
        .audio-controls {
            margin-top: 5px;
            display: flex;
            gap: 5px;
        }
        .audio-control-btn {
            padding: 2px 8px;
            font-size: 12px;
            border-radius: 3px;
            background: #f0f0f0;
            border: 1px solid #ccc;
            cursor: pointer;
        }
        .stop-btn {
            background: #ffeeee;
        }
        .clear-chat-btn {
            position: absolute;
            right: 10px;
            top: 10px;
            padding: 5px 10px;
            font-size: 12px;
            background: #f0f0f0;
            border: 1px solid #ccc;
            border-radius: 3px;
            cursor: pointer;
        }
    `;
    document.head.appendChild(style);

    // Toggle assistant panel
    assistantToggle.addEventListener("click", function() {
        // Toggle the active class to show/hide the panel
        assistantPanel.classList.toggle("active");
        
        // Send ping when panel is opened
        if (assistantPanel.classList.contains("active")) {
            sendInitialPing();
        } else {
            endVoiceChat();
        }
    });

    // Close panel button
    closePanel.addEventListener("click", () => {
        assistantPanel.classList.remove("active");
        endVoiceChat();
    });
    
    // Mode selector - keep all input methods visible in each mode
    modeOptions.forEach(option => {
        option.addEventListener("click", () => {
            // First end any active voice chat
            endVoiceChat();
            
            // Remove active class from all options
            modeOptions.forEach(opt => opt.classList.remove("active"));
            
            // Add active class to clicked option
            option.classList.add("active");
            
            const mode = option.getAttribute("data-mode");
            
            // Handle mode change - now show both text and voice inputs for all modes
            if (mode === "voice") {
                // In voice mode, prioritize voice inputs
                textInputContainer.style.display = "flex"; // Keep text input available
                voiceControl.style.display = "flex";
                endChat.style.display = "none";
                statusEl.style.display = "block";
                avatarContainer.style.display = "none";
            } else if (mode === "avatar") {
                // In avatar mode, show everything
                avatarContainer.style.display = "block";
                textInputContainer.style.display = "flex";
                voiceControl.style.display = "flex";
                endChat.style.display = "none";
                statusEl.style.display = "block";
            } else {
                // Text mode - keep voice input available
                avatarContainer.style.display = "none";
                textInputContainer.style.display = "flex";
                voiceControl.style.display = "flex";
                endChat.style.display = "none";
                statusEl.style.display = "block";
            }
            
            addMessage(`Switched to ${mode} mode (both text and audio processing enabled)`, "system");
        });
    });
    
    // Text input handling
    textInput.addEventListener("keydown", (e) => {
        if (e.key === "Enter" && !e.shiftKey) {
            e.preventDefault();
            const message = textInput.value.trim();
            if (message) {
                sendTextToWebhook(message);
                textInput.value = "";
                textInput.style.height = "auto"; // Reset height
            }
        }
    });
    
    sendBtn.addEventListener("click", () => {
        const message = textInput.value.trim();
        if (message) {
            sendTextToWebhook(message);
            textInput.value = "";
            textInput.style.height = "auto"; // Reset height
        }
    });
    
    // Voice chat controls
    voiceControl.addEventListener("click", () => {
        userEndedChat = false;
        startListening();
    });
    
    // End chat button
    endChat.addEventListener("click", () => {
        endVoiceChat();
    });
    
    // Clear chat button
    clearChatBtn.addEventListener("click", () => {
        clearChat();
    });
    
    // Handle window/tab close
    window.addEventListener("beforeunload", cleanupResources);
}

// Initialize app when DOM is loaded
document.addEventListener("DOMContentLoaded", function() {
    initializeApp();
});
</script>
</body>
</html>